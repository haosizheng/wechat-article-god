import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import json
import time
from datetime import datetime
from typing import Dict, List, Optional
from notion.config import load_config
from notion.api_client import NotionApiClient
from notion.text_processor import TextProcessor
from notion.markdown_processor import MarkdownProcessor
import re
import requests

class ImportCheckpoint:
    def __init__(self, checkpoint_file="import_checkpoint.json"):
        self.checkpoint_file = checkpoint_file
        self.processed_files = set()
        self.processed_articles = {}
        self.failed_imports = {}  # {file_path: {article_title: error_message}}
        self.load_checkpoint()

    def load_checkpoint(self):
        """åŠ è½½æ£€æŸ¥ç‚¹æ–‡ä»¶"""
        try:
            if os.path.exists(self.checkpoint_file):
                with open(self.checkpoint_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.processed_files = set(data.get('processed_files', []))
                    self.processed_articles = {
                        k: set(v) for k, v in data.get('processed_articles', {}).items()
                    }
                    self.failed_imports = data.get('failed_imports', {})
                print(f"ğŸ“‹ å·²åŠ è½½æ£€æŸ¥ç‚¹: {len(self.processed_files)} ä¸ªæ–‡ä»¶, "
                      f"{sum(len(articles) for articles in self.processed_articles.values())} ç¯‡æ–‡ç« , "
                      f"{sum(len(articles) for articles in self.failed_imports.values())} ç¯‡å¤±è´¥")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            self.processed_files = set()
            self.processed_articles = {}
            self.failed_imports = {}
    
    def save_checkpoint(self):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        try:
            data = {
                'processed_files': list(self.processed_files),
                'processed_articles': {
                    k: list(v) for k, v in self.processed_articles.items()
                },
                'failed_imports': self.failed_imports
            }
            with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    def is_file_processed(self, file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å¤„ç†"""
        return file_path in self.processed_files
    
    def is_article_processed(self, file_path, article_title):
        """æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²å¤„ç†"""
        return article_title in self.processed_articles.get(file_path, set())
    
    def mark_file_processed(self, file_path):
        """æ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†"""
        self.processed_files.add(file_path)
        self.save_checkpoint()
    
    def mark_article_processed(self, file_path, article_title):
        """æ ‡è®°æ–‡ç« ä¸ºå·²å¤„ç†"""
        if file_path not in self.processed_articles:
            self.processed_articles[file_path] = set()
        self.processed_articles[file_path].add(article_title)
        self.save_checkpoint()
    
    def mark_import_failed(self, file_path, article_title, error_message):
        """è®°å½•å¯¼å…¥å¤±è´¥çš„æ–‡ç« """
        if file_path not in self.failed_imports:
            self.failed_imports[file_path] = {}
        self.failed_imports[file_path][article_title] = error_message
        self.save_checkpoint()
        print(f"âŒ è®°å½•å¤±è´¥: {article_title}")
    
    def get_failed_imports(self):
        """è·å–æ‰€æœ‰å¤±è´¥çš„å¯¼å…¥"""
        return self.failed_imports
    
    def remove_from_failed(self, file_path, article_title):
        """ä»å¤±è´¥åˆ—è¡¨ä¸­ç§»é™¤ï¼ˆå½“é‡è¯•æˆåŠŸæ—¶ï¼‰"""
        if file_path in self.failed_imports and article_title in self.failed_imports[file_path]:
            del self.failed_imports[file_path][article_title]
            if not self.failed_imports[file_path]:  # å¦‚æœæ–‡ä»¶çš„æ‰€æœ‰æ–‡ç« éƒ½å·²å¤„ç†
                del self.failed_imports[file_path]
            self.save_checkpoint()
            print(f"âœ… ä»å¤±è´¥åˆ—è¡¨ç§»é™¤: {article_title}")

def normalize_text(text):
    """å°†æ–‡æœ¬ä¸­çš„å¤šä¸ªè¿ç»­æ¢è¡Œç¬¦åˆå¹¶ä¸ºä¸€ä¸ª
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        
    Returns:
        str: å¤„ç†åçš„æ–‡æœ¬
    """
    if not text:
        return text
        
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢2ä¸ªæˆ–æ›´å¤šè¿ç»­çš„æ¢è¡Œç¬¦ä¸ºå•ä¸ªæ¢è¡Œç¬¦
    normalized = re.sub(r'\n{2,}', '\n', text)
    return normalized

class NotionDatabaseImporter:
    def __init__(self, notion_token: str, database_id: str):
        self.api_client = NotionApiClient(notion_token, database_id)
        self.text_processor = TextProcessor()
        self.markdown_processor = MarkdownProcessor()

    def update_or_create_page(self, title: str, content: str, publish_date: Optional[str] = None,
                             author: Optional[str] = None, url: Optional[str] = None,
                             base_dir: str = None, summary: Optional[str] = None) -> bool:
        """
        æ›´æ–°å·²å­˜åœ¨çš„é¡µé¢æˆ–åˆ›å»ºæ–°é¡µé¢
        """
        try:
            # æ„å»ºæ–°çš„å±æ€§ï¼ˆåªåŒ…å«æœ‰å€¼çš„å­—æ®µï¼‰
            new_properties = {}
            
            # æ ‡é¢˜æ€»æ˜¯éœ€è¦çš„
            if title:
                new_properties["Title"] = {"title": [{"text": {"content": title}}]}
            
            # å…¶ä»–å­—æ®µåªåœ¨æœ‰å€¼æ—¶æ·»åŠ 
            if author:
                new_properties["Author"] = {"select": {"name": author}}
            if url:
                new_properties["URL"] = {"url": url}
            if publish_date:
                new_properties["Publish Date"] = {"date": {"start": publish_date}}
            if summary:
                # ç¡®ä¿summaryçš„æ¢è¡Œç¬¦è¢«æ­£ç¡®å¤„ç†
                normalized_summary = normalize_text(summary)
                new_properties["Summary"] = {"rich_text": [{"text": {"content": normalized_summary}}]}
            
            # æŸ¥æ‰¾å·²å­˜åœ¨çš„é¡µé¢
            existing_page_id = self.api_client.find_page_by_title(title)
            
            if existing_page_id:
                print(f"    ğŸ“ æ‰¾åˆ°å·²å­˜åœ¨çš„é¡µé¢ï¼Œå‡†å¤‡æ›´æ–°...")
                print(f"    ğŸ“„ é¡µé¢ID: {existing_page_id}")
                
                # è·å–ç°æœ‰å±æ€§
                print(f"    ğŸ“‘ è·å–ç°æœ‰å±æ€§...")
                current_properties = self.api_client.get_page_properties(existing_page_id)
                
                # åˆå¹¶å±æ€§ï¼ˆä¿ç•™æœªæ›´æ–°çš„å­—æ®µï¼‰
                print(f"    ğŸ”„ åˆå¹¶å±æ€§...")
                merged_properties = self.api_client.merge_properties(current_properties, new_properties)
                
                # æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰å†…å®¹
                has_content = False
                try:
                    response = requests.get(
                        f"{self.api_client.base_url}/blocks/{existing_page_id}/children",
                        headers=self.api_client.headers
                    )
                    response.raise_for_status()
                    existing_blocks = response.json().get("results", [])
                    has_content = len(existing_blocks) > 0
                except Exception as e:
                    print(f"    âš ï¸ æ£€æŸ¥é¡µé¢å†…å®¹æ—¶å‡ºé”™: {str(e)}")
                    has_content = True  # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œå‡è®¾æœ‰å†…å®¹ä»¥é¿å…è¦†ç›–
                
                # æ›´æ–°é¡µé¢å±æ€§
                if not self.api_client.update_page_properties(existing_page_id, merged_properties):
                    return False
                
                if not has_content:
                    print(f"    ğŸ“„ é¡µé¢å†…å®¹ä¸ºç©ºï¼Œæ·»åŠ æ–°å†…å®¹...")
                    # å‡†å¤‡å†…å®¹å—
                    content_blocks = self.prepare_content_blocks(title, author, publish_date, url, content)
                    
                    # åˆ†æ‰¹æ·»åŠ æ–°å†…å®¹
                    try:
                        self.api_client.add_blocks_in_batches(existing_page_id, content_blocks)
                        print(f"    âœ… æ–°å†…å®¹å·²æ·»åŠ ")
                    except Exception as e:
                        print(f"    âŒ æ·»åŠ å†…å®¹å¤±è´¥: {str(e)}")
                        if hasattr(e, 'response') and hasattr(e.response, 'text'):
                            error_data = e.response.text
                            print(f"    ğŸ“ é”™è¯¯è¯¦æƒ…: {error_data}")
                        return False
                else:
                    print(f"    â„¹ï¸ é¡µé¢å·²æœ‰å†…å®¹ï¼Œä¿æŒä¸å˜")
                
                print(f"    âœ¨ é¡µé¢æ›´æ–°æˆåŠŸ")
                return True
                
            else:
                # åˆ›å»ºæ–°é¡µé¢
                print(f"    ğŸ“„ åˆ›å»ºæ–°é¡µé¢...")
                content_blocks = self.prepare_content_blocks(title, author, publish_date, url, content)
                new_page_id = self.api_client.create_page(new_properties, content_blocks)
                return new_page_id is not None
            
        except Exception as e:
            print(f"    âŒ æ›´æ–°/åˆ›å»ºé¡µé¢å¤±è´¥: {str(e)}")
            return False

    def prepare_content_blocks(self, title: str, author: str, publish_date: str, url: str, content: str) -> List[Dict]:
        """
        å‡†å¤‡é¡µé¢å†…å®¹å—
        """
        content_blocks = []
        
        # æ·»åŠ æ ‡é¢˜
        content_blocks.append({
            "type": "heading_1",
            "heading_1": {
                "rich_text": [{"type": "text", "text": {"content": title}}]
            }
        })
            
        # æ·»åŠ ä½œè€…å’Œæ—¥æœŸä¿¡æ¯
        info_text = f"ä½œè€…ï¼š{author if author else 'æœªçŸ¥'}"
        if publish_date:
            info_text += f" | å‘å¸ƒæ—¶é—´ï¼š{publish_date}"
        content_blocks.append({
            "type": "paragraph",
            "paragraph": {
                "rich_text": [{"type": "text", "text": {"content": info_text}}]
            }
        })
        
        # æ·»åŠ åŸæ–‡é“¾æ¥
        if url:
            content_blocks.append({
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [
                        {
                            "type": "text",
                            "text": {
                                "content": "åŸæ–‡é“¾æ¥ï¼š",
                            }
                        },
                        {
                            "type": "text",
                            "text": {
                                "content": url,
                                "link": {"url": url}
                            }
                        }
                    ]
                }
            })
        
        # æ·»åŠ åˆ†éš”çº¿
        content_blocks.append({
            "type": "divider",
            "divider": {}
        })
        
        # å¤„ç†æ­£æ–‡å†…å®¹
        if content:
            content_blocks.extend(self.markdown_processor.create_text_block(content))
        
        return content_blocks

    def import_from_json(self, json_file: str, checkpoint: ImportCheckpoint) -> None:
        """ä» JSON æ–‡ä»¶å¯¼å…¥æ–‡ç« åˆ° Notion database"""
        print(f"æ­£åœ¨ä» {json_file} å¯¼å…¥æ–‡ç« ...")
        
        # å¦‚æœæ–‡ä»¶å·²ç»å®Œå…¨å¤„ç†è¿‡ï¼Œè·³è¿‡
        if checkpoint.is_file_processed(json_file):
            print(f"âœ… æ–‡ä»¶å·²å®Œå…¨å¤„ç†è¿‡ï¼Œè·³è¿‡: {json_file}")
            return
        
        # è·å–æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆç”¨äºè§£æç›¸å¯¹å›¾ç‰‡è·¯å¾„ï¼‰
        base_dir = os.path.dirname(os.path.abspath(json_file))
        
        with open(json_file, 'r', encoding='utf-8') as f:
            articles = json.load(f)

        total = len(articles)
        success = 0
        
        for idx, article in enumerate(articles, 1):
            title = article.get('title', 'Untitled')
            print(f"\nå¤„ç†ç¬¬ {idx}/{total} ç¯‡æ–‡ç« : {title}")
            
            # å¦‚æœæ–‡ç« å·²å¤„ç†è¿‡ï¼Œè·³è¿‡
            if checkpoint.is_article_processed(json_file, title):
                print(f"    âœ… æ–‡ç« å·²å¤„ç†è¿‡ï¼Œè·³è¿‡")
                success += 1
                continue
            
            try:
                # ç¡®ä¿æ‰€æœ‰å¿…è¦å­—æ®µéƒ½å­˜åœ¨
                content = article.get('content', '')
                publish_date = article.get('publish_time', '')
                author = article.get('author', 'Unknown')
                url = article.get('url', '')
                summary = article.get('summary', '')
                
                # è½¬æ¢å‘å¸ƒæ—¥æœŸæ ¼å¼
                if publish_date:
                    publish_date = self.text_processor.convert_chinese_date_to_iso(publish_date)
                
                # å¤„ç†contentå’Œsummaryçš„æ¢è¡Œç¬¦
                if 'content' in article:
                    article['content'] = normalize_text(article['content'])
                if 'summary' in article:
                    article['summary'] = normalize_text(article['summary'])
                
                # æ›´æ–°æˆ–åˆ›å»ºé¡µé¢
                if self.update_or_create_page(
                    title, content, publish_date, author, url, base_dir, summary
                ):
                    success += 1
                    # æ ‡è®°æ–‡ç« ä¸ºå·²å¤„ç†
                    checkpoint.mark_article_processed(json_file, title)
                
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
                # è®°å½•å¤±è´¥çš„æ–‡ç« 
                checkpoint.mark_import_failed(json_file, title, str(e))
            
            # æ·»åŠ å»¶è¿Ÿä»¥é¿å…è¶…å‡º Notion API é™åˆ¶
            time.sleep(0.5)
        
        # å¦‚æœæ‰€æœ‰æ–‡ç« éƒ½å¤„ç†æˆåŠŸï¼Œæ ‡è®°æ–‡ä»¶ä¸ºå·²å¤„ç†
        if success == total:
            checkpoint.mark_file_processed(json_file)

        print(f"\nå¯¼å…¥å®Œæˆ: {success}/{total} ç¯‡æ–‡ç« æˆåŠŸå¯¼å…¥/æ›´æ–°")

def main():
    # ä»é…ç½®æ–‡ä»¶åŠ è½½è®¾ç½®
    config = load_config()
    
    if not config:
        return
    
    notion_token = config.get("notion_token")
    database_id = config.get("database_id")
    
    if not notion_token or not database_id:
        print("Error: Please set notion_token and database_id in notion_config.json")
        return

    # åˆå§‹åŒ–æ£€æŸ¥ç‚¹ç³»ç»Ÿ
    checkpoint = ImportCheckpoint()
    importer = NotionDatabaseImporter(notion_token, database_id)
    
    # æŸ¥æ‰¾Outputæ–‡ä»¶å¤¹
    output_dir = os.path.join(os.path.dirname(__file__), "Output")
    if not os.path.exists(output_dir):
        print(f"âŒ Outputæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {output_dir}")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰å­æ–‡ä»¶å¤¹ä¸­çš„articles_detailed.jsonæ–‡ä»¶
    json_files = []
    for root, dirs, files in os.walk(output_dir):
        if "articles_detailed.json" in files:
            json_files.append(os.path.join(root, "articles_detailed.json"))
    
    if not json_files:
        print("âŒ åœ¨Outputæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•articles_detailed.jsonæ–‡ä»¶")
        return
    
    # æ˜¾ç¤ºæ‰¾åˆ°çš„æ–‡ä»¶å’Œå¤„ç†è¿›åº¦
    print(f"\nğŸ“ æ‰¾åˆ° {len(json_files)} ä¸ªæ–‡ç« åˆ—è¡¨æ–‡ä»¶:")
    for i, f in enumerate(json_files, 1):
        folder_name = os.path.basename(os.path.dirname(f))
        status = "âœ… å·²å¤„ç†" if checkpoint.is_file_processed(f) else "â³ å¾…å¤„ç†"
        if not checkpoint.is_file_processed(f) and f in checkpoint.processed_articles:
            processed_count = len(checkpoint.processed_articles[f])
            with open(f, 'r', encoding='utf-8') as file:
                total_count = len(json.load(file))
            status = f"ğŸ”„ è¿›è¡Œä¸­ ({processed_count}/{total_count})"
        print(f"{i}. {folder_name} - {status}")
    
    # ç¡®è®¤æ˜¯å¦ç»§ç»­
    confirm = input("\næ˜¯å¦ç»§ç»­å¯¼å…¥è¿™äº›æ–‡ä»¶åˆ°Notionï¼Ÿ(y/n): ").strip().lower()
    if confirm not in ['y', 'yes', 'æ˜¯']:
        print("ğŸ‘‹ å·²å–æ¶ˆå¯¼å…¥")
        return
    
    # å¯¼å…¥æ‰€æœ‰æ–‡ä»¶
    total_success = 0
    total_articles = 0
    
    for i, json_file in enumerate(json_files, 1):
        folder_name = os.path.basename(os.path.dirname(json_file))
        print(f"\n{'='*50}")
        print(f"å¤„ç†ç¬¬ {i}/{len(json_files)} ä¸ªæ–‡ä»¶: {folder_name}")
        print(f"{'='*50}")
        
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹ä»¥è·å–æ–‡ç« æ•°é‡
            with open(json_file, 'r', encoding='utf-8') as f:
                articles = json.load(f)
                total_articles += len(articles)
            
            # å¯¼å…¥æ–‡ä»¶
            print(f"å¼€å§‹å¯¼å…¥ {json_file}...")
            importer.import_from_json(json_file, checkpoint)
            print(f"âœ… {folder_name} å¯¼å…¥å®Œæˆ")
            total_success += 1
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
        
        # åœ¨å¤„ç†æ–‡ä»¶ä¹‹é—´æ·»åŠ çŸ­æš‚å»¶è¿Ÿ
        if i < len(json_files):
            print("ç­‰å¾…3ç§’åå¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶...")
            time.sleep(3)
    
    # æ˜¾ç¤ºæ€»ä½“å¯¼å…¥ç»“æœ
    print(f"\nğŸ“Š å¯¼å…¥æ€»ç»“:")
    print(f"- æˆåŠŸå¤„ç†æ–‡ä»¶: {total_success}/{len(json_files)}")
    print(f"- æ€»æ–‡ç« æ•°é‡: {total_articles}")
    print("âœ¨ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ")

if __name__ == "__main__":
    main() 