import json
import os
from datetime import datetime
import requests
from typing import Dict, List, Optional, Union
import re
import mimetypes
import time
import base64

class NotionDatabaseImporter:
    def __init__(self, notion_token: str, database_id: str):
        """
        åˆå§‹åŒ– Notion API å®¢æˆ·ç«¯
        
        Args:
            notion_token: Notion API integration token
            database_id: ç›®æ ‡ database çš„ ID
        """
        self.notion_token = notion_token
        self.database_id = database_id
        self.headers = {
            "Authorization": f"Bearer {notion_token}",
            "Content-Type": "application/json",
            "Notion-Version": "2022-06-28"
        }
        self.base_url = "https://api.notion.com/v1"

    def clean_text(self, text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬å†…å®¹ï¼š
        1. å°†å¤šä¸ªè¿ç»­çš„æ¢è¡Œç¬¦æ›¿æ¢ä¸ºå•ä¸ªæ¢è¡Œç¬¦
        2. åˆ é™¤æ®µè½å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½å­—ç¬¦
        3. ç¡®ä¿æ®µè½ä¹‹é—´åªæœ‰ä¸€ä¸ªç©ºè¡Œ
        """
        if not text:
            return ""
        
        # ç»Ÿä¸€æ¢è¡Œç¬¦ä¸º \n
        text = text.replace('\r\n', '\n').replace('\r', '\n')
        
        # å°†ä¸‰ä¸ªæˆ–æ›´å¤šè¿ç»­çš„æ¢è¡Œç¬¦æ›¿æ¢ä¸ºä¸¤ä¸ªæ¢è¡Œç¬¦
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        # æ¸…ç†æ¯ä¸ªæ®µè½çš„é¦–å°¾ç©ºç™½å­—ç¬¦
        paragraphs = [p.strip() for p in text.split('\n\n')]
        
        # è¿‡æ»¤æ‰ç©ºæ®µè½
        paragraphs = [p for p in paragraphs if p]
        
        # ç”¨ä¸¤ä¸ªæ¢è¡Œç¬¦é‡æ–°è¿æ¥æ®µè½
        return '\n\n'.join(paragraphs)

    def parse_date(self, date_str: str) -> Optional[str]:
        """
        è§£æå¤šç§æ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²ï¼Œè¿”å›æ ‡å‡†æ ¼å¼ (YYYY-MM-DD)
        """
        if not date_str:
            return None

        # æ¸…ç†æ—¥æœŸå­—ç¬¦ä¸²
        date_str = date_str.strip().replace('ï¼š', ':').replace('\u3000', ' ').replace('\xa0', ' ')
        
        # å°è¯•ä¸åŒçš„æ—¥æœŸæ ¼å¼
        date_formats = [
            # æ ‡å‡†æ ¼å¼
            "%Y-%m-%d",
            "%Y/%m/%d",
            "%Y.%m.%d",
            # å¸¦æ—¶é—´çš„æ ¼å¼
            "%Y-%m-%d %H:%M:%S",
            "%Y-%m-%d %H:%M",
            "%Y/%m/%d %H:%M:%S",
            "%Y/%m/%d %H:%M",
            "%Y.%m.%d %H:%M:%S",
            "%Y.%m.%d %H:%M",
            # ä¸­æ–‡æ ¼å¼
            "%Yå¹´%mæœˆ%dæ—¥",
            "%Yå¹´%mæœˆ%dæ—¥ %H:%M",
            "%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S"
        ]

        for fmt in date_formats:
            try:
                dt = datetime.strptime(date_str, fmt)
                return dt.strftime("%Y-%m-%d")
            except ValueError:
                continue

        # å¦‚æœä¸Šè¿°æ ¼å¼éƒ½ä¸åŒ¹é…ï¼Œå°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ—¥æœŸ
        # åŒ¹é… YYYY-MM-DD æˆ– YYYY/MM/DD æˆ– YYYY.MM.DD æ ¼å¼
        date_pattern = r'(\d{4})[-./å¹´](\d{1,2})[-./æœˆ](\d{1,2})[æ—¥]?'
        match = re.search(date_pattern, date_str)
        if match:
            year, month, day = match.groups()
            try:
                dt = datetime(int(year), int(month), int(day))
                return dt.strftime("%Y-%m-%d")
            except ValueError:
                pass

        print(f"Warning: Could not parse date string: {date_str}")
        return None

    def upload_image_to_notion(self, image_path: str) -> str:
        """
        å°†æœ¬åœ°å›¾ç‰‡è½¬æ¢ä¸º base64 URL
        è¿”å›: å›¾ç‰‡çš„ base64 URL
        """
        try:
            from PIL import Image
            import io
            import base64
            
            # æ‰“å¼€å¹¶å‹ç¼©å›¾ç‰‡
            with Image.open(image_path) as img:
                # è½¬æ¢ä¸º RGB æ¨¡å¼ï¼ˆå¤„ç† RGBA å›¾ç‰‡ï¼‰
                if img.mode in ('RGBA', 'LA'):
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    background.paste(img, mask=img.split()[-1])
                    img = background
                elif img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # å¦‚æœå›¾ç‰‡å¤ªå¤§ï¼Œè¿›è¡Œå‹ç¼©
                max_size = (800, 800)  # æœ€å¤§å°ºå¯¸
                if img.size[0] > max_size[0] or img.size[1] > max_size[1]:
                    img.thumbnail(max_size, Image.Resampling.LANCZOS)
                
                # è½¬æ¢ä¸º JPEG æ ¼å¼å¹¶å‹ç¼©
                output = io.BytesIO()
                img.save(output, format='JPEG', quality=85, optimize=True)
                image_data = output.getvalue()
            
            # è½¬æ¢ä¸º base64
            base64_data = base64.b64encode(image_data).decode('utf-8')
            image_url = f"data:image/jpeg;base64,{base64_data}"
            
            return image_url
        
        except Exception as e:
            print(f"    âš ï¸ å›¾ç‰‡å¤„ç†å¤±è´¥ ({image_path}): {e}")
            return None

    def markdown_to_blocks(self, markdown_text: str, base_dir: str = None) -> List[Dict]:
        """
        å°†Markdownæ–‡æœ¬è½¬æ¢ä¸ºNotionå—
        base_dir: ç”¨äºè§£æç›¸å¯¹å›¾ç‰‡è·¯å¾„çš„åŸºç¡€ç›®å½•
        """
        if not markdown_text:
            return []

        blocks = []
        current_list_items = []
        in_code_block = False
        code_block_content = []
        
        # æ¸…ç†æ–‡æœ¬ï¼Œç»Ÿä¸€æ¢è¡Œç¬¦
        markdown_text = markdown_text.replace('\r\n', '\n').replace('\r', '\n')
        lines = markdown_text.split('\n')
        
        i = 0
        while i < len(lines):
            line = lines[i].rstrip()
            
            # è·³è¿‡ç©ºè¡Œ
            if not line:
                i += 1
                continue
            
            # å¤„ç†ä»£ç å—
            if line.startswith('```'):
                if not in_code_block:
                    in_code_block = True
                    code_block_content = []
                    i += 1
                    continue
                else:
                    blocks.append({
                        "type": "code",
                        "code": {
                            "language": "plain text",
                            "rich_text": [{
                                "type": "text",
                                "text": {"content": '\n'.join(code_block_content)}
                            }]
                        }
                    })
                    in_code_block = False
                    i += 1
                    continue
            
            if in_code_block:
                code_block_content.append(line)
                i += 1
                continue
            
            # å¤„ç†æ ‡é¢˜
            header_match = re.match(r'^(#{1,4})\s+(.+)$', line)
            if header_match:
                level = len(header_match.group(1))
                text = header_match.group(2)
                blocks.append({
                    "type": f"heading_{level}",
                    f"heading_{level}": {
                        "rich_text": [{"type": "text", "text": {"content": text}}]
                    }
                })
                i += 1
                continue
            
            # å¤„ç†å¼•ç”¨
            if line.startswith('> '):
                quote_text = line[2:]
                blocks.append({
                    "type": "quote",
                    "quote": {
                        "rich_text": [{"type": "text", "text": {"content": quote_text}}]
                    }
                })
                i += 1
                continue
            
            # å¤„ç†æ— åºåˆ—è¡¨
            if line.startswith('- ') or line.startswith('* '):
                list_text = line[2:]
                current_list_items.append(list_text)
                
                # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦ä¹Ÿæ˜¯åˆ—è¡¨é¡¹
                if i + 1 >= len(lines) or not (lines[i+1].startswith('- ') or lines[i+1].startswith('* ')):
                    # åˆ›å»ºå®Œæ•´çš„åˆ—è¡¨å—
                    blocks.append({
                        "type": "bulleted_list_item",
                        "bulleted_list_item": {
                            "rich_text": [{"type": "text", "text": {"content": list_text}}]
                        }
                    })
                    current_list_items = []
                i += 1
                continue
            
            # å¤„ç†æœ‰åºåˆ—è¡¨
            ordered_list_match = re.match(r'^\d+\.\s+(.+)$', line)
            if ordered_list_match:
                list_text = ordered_list_match.group(1)
                blocks.append({
                    "type": "numbered_list_item",
                    "numbered_list_item": {
                        "rich_text": [{"type": "text", "text": {"content": list_text}}]
                    }
                })
                i += 1
                continue
            
            # å¤„ç†å›¾ç‰‡
            image_match = re.match(r'!\[([^\]]*)\]\(([^)]+)\)', line)
            if image_match:
                alt_text = image_match.group(1)
                image_path = image_match.group(2)
                
                # å¤„ç†æœ¬åœ°å›¾ç‰‡è·¯å¾„
                if not image_path.startswith(('http://', 'https://', 'data:')):
                    if base_dir:
                        # å¦‚æœæä¾›äº†åŸºç¡€ç›®å½•ï¼Œå°è¯•ä»é‚£é‡ŒåŠ è½½å›¾ç‰‡
                        full_path = os.path.join(base_dir, image_path)
                        if os.path.exists(full_path):
                            # å¤„ç†å›¾ç‰‡å¹¶è·å– base64 URL
                            image_url = self.upload_image_to_notion(full_path)
                            if image_url:
                                blocks.append({
                                    "type": "paragraph",
                                    "paragraph": {
                                        "rich_text": [{
                                            "type": "text",
                                            "text": {
                                                "content": f"[{alt_text}]",
                                            }
                                        }]
                                    }
                                })
                                blocks.append({
                                    "type": "image",
                                    "image": {
                                        "type": "external",
                                        "external": {
                                            "url": image_url
                                        }
                                    }
                                })
                elif image_path.startswith(('http://', 'https://', 'data:')):
                    blocks.append({
                        "type": "paragraph",
                        "paragraph": {
                            "rich_text": [{
                                "type": "text",
                                "text": {
                                    "content": f"[{alt_text}]",
                                }
                            }]
                        }
                    })
                    blocks.append({
                        "type": "image",
                        "image": {
                            "type": "external",
                            "external": {
                                "url": image_path
                            }
                        }
                    })
                i += 1
                continue
            
            # å¤„ç†æ™®é€šæ®µè½ï¼ˆåŒ…å«å†…è”æ ¼å¼ï¼‰
            text = line
            rich_text_elements = []
            
            # å¤„ç†åŠ ç²—
            bold_segments = re.split(r'(\*\*.*?\*\*)', text)
            for segment in bold_segments:
                if segment.startswith('**') and segment.endswith('**'):
                    content = segment[2:-2]
                    rich_text_elements.append({
                        "type": "text",
                        "text": {"content": content},
                        "annotations": {"bold": True}
                    })
                else:
                    if segment:
                        rich_text_elements.append({
                            "type": "text",
                            "text": {"content": segment}
                        })
            
            if rich_text_elements:
                blocks.append({
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": rich_text_elements
                    }
                })
            
            i += 1
        
        return blocks

    def create_page(self, title: str, content: str, publish_date: Optional[str] = None,
                   author: Optional[str] = None, url: Optional[str] = None) -> Dict:
        """
        åœ¨ Notion database ä¸­åˆ›å»ºæ–°é¡µé¢ï¼Œå°†æ–‡ç« å†…å®¹æ”¾åœ¨é¡µé¢æ­£æ–‡ä¸­
        
        Args:
            title: æ–‡ç« æ ‡é¢˜
            content: æ–‡ç« æ­£æ–‡
            publish_date: å‘å¸ƒæ—¥æœŸ
            author: ä½œè€…
            url: åŸæ–‡é“¾æ¥
        """
        try:
            # æ„å»ºé¡µé¢å±æ€§
            properties = {
                "æ ‡é¢˜": {"title": [{"text": {"content": title}}]},
            }
            
            # è§£æå¹¶æ·»åŠ å‘å¸ƒæ—¥æœŸ
            if publish_date:
                formatted_date = self.parse_date(publish_date)
                if formatted_date:
                    properties["å‘å¸ƒæ—¥æœŸ"] = {"date": {"start": formatted_date}}
            
            if author:
                properties["ä½œè€…"] = {"select": {"name": author}}
            
            if url:
                properties["URL"] = {"url": url}

            # å°†Markdownå†…å®¹è½¬æ¢ä¸ºNotionå—
            children = self.markdown_to_blocks(content)

            # åˆ›å»ºé¡µé¢
            payload = {
                "parent": {"database_id": self.database_id},
                "properties": properties,
                "children": children
            }

            response = requests.post(
                f"{self.base_url}/pages",
                headers=self.headers,
                json=payload
            )

            if response.status_code != 200:
                print(f"Error creating page for {title}: {response.text}")
                return None

            return response.json()
            
        except Exception as e:
            print(f"Error creating page: {str(e)}")
            return None

    def convert_chinese_date_to_iso(self, date_str: str) -> str:
        """
        å°†ä¸­æ–‡æ—¥æœŸæ ¼å¼è½¬æ¢ä¸º ISO 8601 æ ¼å¼
        ä¾‹å¦‚ï¼š'2025å¹´02æœˆ07æ—¥ 17:40' -> '2025-02-07T17:40:00Z'
        """
        try:
            # å¤„ç†ä¸­æ–‡æ—¥æœŸæ ¼å¼
            date_str = date_str.replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
            # è§£ææ—¥æœŸæ—¶é—´
            dt = datetime.strptime(date_str, '%Y-%m-%d %H:%M')
            # è½¬æ¢ä¸º ISO æ ¼å¼
            return dt.strftime('%Y-%m-%dT%H:%M:00Z')
        except Exception as e:
            print(f"    âš ï¸ æ—¥æœŸè½¬æ¢å¤±è´¥: {date_str} -> {str(e)}")
            return None

    def split_text_into_chunks(self, text: str, max_length: int = 2000) -> List[str]:
        """
        å°†é•¿æ–‡æœ¬åˆ†å‰²æˆä¸è¶…è¿‡æŒ‡å®šé•¿åº¦çš„å—
        """
        # å¦‚æœæ–‡æœ¬é•¿åº¦åœ¨é™åˆ¶å†…ï¼Œç›´æ¥è¿”å›
        if len(text) <= max_length:
            return [text]
        
        chunks = []
        current_chunk = ""
        
        # æŒ‰å¥å­åˆ†å‰²ï¼ˆç”¨ä¸­æ–‡å¥å·ã€è‹±æ–‡å¥å·ã€æ„Ÿå¹å·ã€é—®å·ä½œä¸ºåˆ†éš”ç¬¦ï¼‰
        sentences = re.split('([ã€‚.!?ï¼ï¼Ÿ])', text)
        
        for i in range(0, len(sentences), 2):
            sentence = sentences[i]
            # å¦‚æœæœ‰æ ‡ç‚¹ç¬¦å·ï¼ŒåŠ ä¸Šæ ‡ç‚¹
            if i + 1 < len(sentences):
                sentence += sentences[i + 1]
                
            # å¦‚æœå½“å‰å—åŠ ä¸Šæ–°å¥å­ä¼šè¶…å‡ºé•¿åº¦é™åˆ¶
            if len(current_chunk) + len(sentence) > max_length:
                if current_chunk:
                    chunks.append(current_chunk)
                    current_chunk = sentence
                else:
                    # å¦‚æœå•ä¸ªå¥å­è¶…è¿‡é•¿åº¦é™åˆ¶ï¼Œå¼ºåˆ¶åˆ†å‰²
                    while len(sentence) > max_length:
                        chunks.append(sentence[:max_length])
                        sentence = sentence[max_length:]
                    if sentence:
                        current_chunk = sentence
            else:
                current_chunk += sentence
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks

    def process_inline_markdown(self, text: str) -> List[Dict]:
        """
        å¤„ç†å†…è” Markdown æ ¼å¼ï¼ŒåŒ…æ‹¬åŠ ç²—ã€æ–œä½“ç­‰
        """
        rich_text_elements = []
        
        # ä¿å­˜å½“å‰å¤„ç†ä½ç½®
        current_pos = 0
        
        # æŸ¥æ‰¾æ‰€æœ‰æ ¼å¼æ ‡è®°
        patterns = [
            (r'\*\*(.+?)\*\*', {'bold': True}),  # åŠ ç²—
            (r'\*(.+?)\*', {'italic': True}),     # æ–œä½“
            (r'`(.+?)`', {'code': True}),         # ä»£ç 
            (r'~~(.+?)~~', {'strikethrough': True}),  # åˆ é™¤çº¿
            (r'\[(.+?)\]\((.+?)\)', None)         # é“¾æ¥
        ]
        
        while current_pos < len(text):
            earliest_match = None
            earliest_pos = len(text)
            matched_pattern = None
            
            # æŸ¥æ‰¾æœ€æ—©å‡ºç°çš„æ ¼å¼æ ‡è®°
            for pattern, _ in patterns:
                match = re.search(pattern, text[current_pos:])
                if match and current_pos + match.start() < earliest_pos:
                    earliest_match = match
                    earliest_pos = current_pos + match.start()
                    matched_pattern = pattern
            
            if earliest_match and earliest_pos > current_pos:
                # æ·»åŠ æ ¼å¼æ ‡è®°ä¹‹å‰çš„æ™®é€šæ–‡æœ¬
                if text[current_pos:earliest_pos].strip():
                    rich_text_elements.append({
                        "type": "text",
                        "text": {"content": text[current_pos:earliest_pos]}
                    })
            
            if earliest_match:
                # å¤„ç†æ‰¾åˆ°çš„æ ¼å¼
                pattern_idx = next(i for i, (p, _) in enumerate(patterns) if p == matched_pattern)
                _, annotations = patterns[pattern_idx]
                
                if annotations:  # å¤„ç†åŠ ç²—ã€æ–œä½“ç­‰
                    content = earliest_match.group(1)
                    element = {
                        "type": "text",
                        "text": {"content": content},
                        "annotations": annotations
                    }
                    rich_text_elements.append(element)
                else:  # å¤„ç†é“¾æ¥
                    if matched_pattern == r'\[(.+?)\]\((.+?)\)':
                        text_content = earliest_match.group(1)
                        url = earliest_match.group(2)
                        element = {
                            "type": "text",
                            "text": {
                                "content": text_content,
                                "link": {"url": url}
                            }
                        }
                        rich_text_elements.append(element)
                
                current_pos = earliest_pos + len(earliest_match.group(0))
            else:
                # æ·»åŠ å‰©ä½™çš„æ–‡æœ¬
                if text[current_pos:].strip():
                    rich_text_elements.append({
                        "type": "text",
                        "text": {"content": text[current_pos:]}
                    })
                break
        
        return rich_text_elements

    def create_text_block(self, text: str) -> List[Dict]:
        """
        åˆ›å»ºæ–‡æœ¬å—ï¼Œå¤„ç†é•¿åº¦é™åˆ¶å’Œ Markdown æ ¼å¼
        """
        chunks = self.split_text_into_chunks(text)
        blocks = []
        
        for chunk in chunks:
            # å¤„ç†å†…è” Markdown æ ¼å¼
            rich_text_elements = self.process_inline_markdown(chunk)
            
            blocks.append({
                "type": "paragraph",
                "paragraph": {
                    "rich_text": rich_text_elements
                }
            })
        
        return blocks

    def find_page_by_title(self, title: str) -> Optional[str]:
        """
        åœ¨æ•°æ®åº“ä¸­æŸ¥æ‰¾æŒ‡å®šæ ‡é¢˜çš„é¡µé¢
        è¿”å›: é¡µé¢ IDï¼ˆå¦‚æœæ‰¾åˆ°ï¼‰
        """
        try:
            # ä½¿ç”¨ Notion æœç´¢ API
            response = requests.post(
                "https://api.notion.com/v1/databases/" + self.database_id + "/query",
                headers=self.headers,
                json={
                    "filter": {
                        "property": "Title",
                        "title": {
                            "equals": title
                        }
                    }
                }
            )
            response.raise_for_status()
            results = response.json().get("results", [])
            
            if results:
                # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„é¡µé¢ ID
                return results[0]["id"]
            
            return None
            
        except Exception as e:
            print(f"    âš ï¸ æŸ¥æ‰¾é¡µé¢å¤±è´¥: {e}")
            return None

    def get_page_properties(self, page_id: str) -> Dict:
        """
        è·å–é¡µé¢çš„ç°æœ‰å±æ€§
        """
        try:
            response = requests.get(
                f"https://api.notion.com/v1/pages/{page_id}",
                headers=self.headers
            )
            response.raise_for_status()
            return response.json().get("properties", {})
        except Exception as e:
            print(f"    âš ï¸ è·å–é¡µé¢å±æ€§å¤±è´¥: {e}")
            return {}

    def merge_properties(self, old_props: Dict, new_props: Dict) -> Dict:
        """
        åˆå¹¶æ–°æ—§å±æ€§ï¼Œä¿ç•™æ—§å±æ€§ä¸­æ–°å±æ€§æ²¡æœ‰çš„å€¼
        """
        merged = old_props.copy()
        
        # æ›´æ–°æ–°å±æ€§ä¸­æœ‰å€¼çš„å­—æ®µ
        for key, new_value in new_props.items():
            if key in merged:
                # æ£€æŸ¥æ–°å€¼æ˜¯å¦ä¸ºç©º
                if key == "Title" and new_value.get("title"):
                    merged[key] = new_value
                elif key == "Author" and new_value.get("select", {}).get("name"):
                    merged[key] = new_value
                elif key == "URL" and new_value.get("url"):
                    merged[key] = new_value
                elif key == "Publish Date" and new_value.get("date", {}).get("start"):
                    merged[key] = new_value
        
        return merged

    def update_or_create_page(self, title: str, content: str, publish_date: Optional[str] = None,
                             author: Optional[str] = None, url: Optional[str] = None,
                             base_dir: str = None) -> bool:
        """
        æ›´æ–°å·²å­˜åœ¨çš„é¡µé¢æˆ–åˆ›å»ºæ–°é¡µé¢
        """
        try:
            # æ„å»ºæ–°çš„å±æ€§
            new_properties = {
                "Title": {"title": [{"text": {"content": title}}]},
                "Author": {"select": {"name": author}} if author else None,
                "URL": {"url": url} if url else None,
                "Publish Date": {"date": {"start": publish_date}} if publish_date else None
            }
            
            # ç§»é™¤ç©ºå€¼
            new_properties = {k: v for k, v in new_properties.items() if v is not None}
            
            # æŸ¥æ‰¾å·²å­˜åœ¨çš„é¡µé¢
            existing_page_id = self.find_page_by_title(title)
            
            if existing_page_id:
                print(f"    ğŸ“ æ‰¾åˆ°å·²å­˜åœ¨çš„é¡µé¢ï¼Œå‡†å¤‡æ›´æ–°...")
                print(f"    ğŸ“„ é¡µé¢ID: {existing_page_id}")
                
                try:
                    # é¦–å…ˆåˆ é™¤æ‰€æœ‰ç°æœ‰å†…å®¹
                    print(f"    ğŸ—‘ï¸ åˆ é™¤ç°æœ‰å†…å®¹...")
                    response = requests.get(
                        f"https://api.notion.com/v1/blocks/{existing_page_id}/children",
                        headers=self.headers
                    )
                    response.raise_for_status()
                    existing_blocks = response.json().get("results", [])
                    
                    for block in existing_blocks:
                        requests.delete(
                            f"https://api.notion.com/v1/blocks/{block['id']}",
                            headers=self.headers
                        )
                    print(f"    âœ… ç°æœ‰å†…å®¹å·²åˆ é™¤")
                    
                    # å‡†å¤‡å†…å®¹å—
                    print(f"    ğŸ“ å‡†å¤‡æ–°å†…å®¹...")
                    content_blocks = []
                    
                    # æ·»åŠ æ ‡é¢˜
                    content_blocks.append({
                        "type": "heading_1",
                        "heading_1": {
                            "rich_text": [{"type": "text", "text": {"content": title}}]
                        }
                    })
                    
                    # æ·»åŠ ä½œè€…å’Œæ—¥æœŸä¿¡æ¯
                    info_text = f"ä½œè€…ï¼š{author}"
                    if publish_date:
                        info_text += f" | å‘å¸ƒæ—¶é—´ï¼š{publish_date}"
                    content_blocks.append({
                        "type": "paragraph",
                        "paragraph": {
                            "rich_text": [{"type": "text", "text": {"content": info_text}}]
                        }
                    })
                    
                    # æ·»åŠ åŸæ–‡é“¾æ¥
                    if url:
                        content_blocks.append({
                            "type": "paragraph",
                            "paragraph": {
                                "rich_text": [
                                    {
                                        "type": "text",
                                        "text": {
                                            "content": "åŸæ–‡é“¾æ¥ï¼š",
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": {
                                            "content": url,
                                            "link": {"url": url}
                                        }
                                    }
                                ]
                            }
                        })
                    
                    # æ·»åŠ åˆ†éš”çº¿
                    content_blocks.append({
                        "type": "divider",
                        "divider": {}
                    })
                    
                    # å¤„ç†æ­£æ–‡å†…å®¹
                    if content:
                        content_blocks.extend(self.create_text_block(content))
                    
                    # æ›´æ–°é¡µé¢å±æ€§
                    print(f"    ğŸ“ æ›´æ–°é¡µé¢å±æ€§...")
                    update_data = {
                        "properties": new_properties
                    }
                    
                    response = requests.patch(
                        f"https://api.notion.com/v1/pages/{existing_page_id}",
                        headers=self.headers,
                        json=update_data
                    )
                    response.raise_for_status()
                    print(f"    âœ… é¡µé¢å±æ€§å·²æ›´æ–°")
                    
                    # æ·»åŠ æ–°å†…å®¹
                    print(f"    ğŸ“ æ·»åŠ æ–°å†…å®¹...")
                    response = requests.patch(
                        f"https://api.notion.com/v1/blocks/{existing_page_id}/children",
                        headers=self.headers,
                        json={"children": content_blocks}
                    )
                    response.raise_for_status()
                    print(f"    âœ… æ–°å†…å®¹å·²æ·»åŠ ")
                    
                    print(f"    âœ¨ é¡µé¢æ›´æ–°æˆåŠŸ")
                    return True
                    
                except requests.exceptions.RequestException as e:
                    print(f"    âŒ APIè¯·æ±‚å¤±è´¥: {str(e)}")
                    if hasattr(e.response, 'text'):
                        error_data = e.response.text
                        print(f"    ğŸ“ é”™è¯¯è¯¦æƒ…: {error_data}")
                    return False
                    
            else:
                print(f"    ğŸ“„ åˆ›å»ºæ–°é¡µé¢...")
                try:
                    # åˆ›å»ºæ–°é¡µé¢
                    page_data = {
                        "parent": {"database_id": self.database_id},
                        "properties": new_properties,
                        "children": []
                    }
                    
                    response = requests.post(
                        "https://api.notion.com/v1/pages",
                        headers=self.headers,
                        json=page_data
                    )
                    response.raise_for_status()
                    
                    new_page_id = response.json().get("id")
                    print(f"    âœ… æ–°é¡µé¢åˆ›å»ºæˆåŠŸï¼ŒID: {new_page_id}")
                    
                    # æ·»åŠ å†…å®¹
                    content_blocks = []
                    
                    # æ·»åŠ æ ‡é¢˜
                    content_blocks.append({
                        "type": "heading_1",
                        "heading_1": {
                            "rich_text": [{"type": "text", "text": {"content": title}}]
                        }
                    })
                    
                    # æ·»åŠ ä½œè€…å’Œæ—¥æœŸä¿¡æ¯
                    info_text = f"ä½œè€…ï¼š{author}"
                    if publish_date:
                        info_text += f" | å‘å¸ƒæ—¶é—´ï¼š{publish_date}"
                    content_blocks.append({
                        "type": "paragraph",
                        "paragraph": {
                            "rich_text": [{"type": "text", "text": {"content": info_text}}]
                        }
                    })
                    
                    # æ·»åŠ åŸæ–‡é“¾æ¥
                    if url:
                        content_blocks.append({
                            "type": "paragraph",
                            "paragraph": {
                                "rich_text": [
                                    {
                                        "type": "text",
                                        "text": {
                                            "content": "åŸæ–‡é“¾æ¥ï¼š",
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": {
                                            "content": url,
                                            "link": {"url": url}
                                        }
                                    }
                                ]
                            }
                        })
                    
                    # æ·»åŠ åˆ†éš”çº¿
                    content_blocks.append({
                        "type": "divider",
                        "divider": {}
                    })
                    
                    # å¤„ç†æ­£æ–‡å†…å®¹
                    if content:
                        content_blocks.extend(self.create_text_block(content))
                    
                    # æ·»åŠ å†…å®¹
                    print(f"    ğŸ“ æ·»åŠ é¡µé¢å†…å®¹...")
                    response = requests.patch(
                        f"https://api.notion.com/v1/blocks/{new_page_id}/children",
                        headers=self.headers,
                        json={"children": content_blocks}
                    )
                    response.raise_for_status()
                    print(f"    âœ… å†…å®¹æ·»åŠ æˆåŠŸ")
                    
                    return True
                    
                except requests.exceptions.RequestException as e:
                    print(f"    âŒ APIè¯·æ±‚å¤±è´¥: {str(e)}")
                    if hasattr(e.response, 'text'):
                        error_data = e.response.text
                        print(f"    ğŸ“ é”™è¯¯è¯¦æƒ…: {error_data}")
                    return False
            
        except Exception as e:
            print(f"    âŒ æ›´æ–°/åˆ›å»ºé¡µé¢å¤±è´¥: {str(e)}")
            return False

    def import_from_json(self, json_file: str) -> None:
        """ä» JSON æ–‡ä»¶å¯¼å…¥æ–‡ç« åˆ° Notion database"""
        print(f"æ­£åœ¨ä» {json_file} å¯¼å…¥æ–‡ç« ...")
        
        # è·å–æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆç”¨äºè§£æç›¸å¯¹å›¾ç‰‡è·¯å¾„ï¼‰
        base_dir = os.path.dirname(os.path.abspath(json_file))
        
        with open(json_file, 'r', encoding='utf-8') as f:
            articles = json.load(f)

        total = len(articles)
        success = 0
        
        for idx, article in enumerate(articles, 1):
            print(f"\nå¤„ç†ç¬¬ {idx}/{total} ç¯‡æ–‡ç« : {article.get('title', 'Untitled')}")
            
            try:
                # ç¡®ä¿æ‰€æœ‰å¿…è¦å­—æ®µéƒ½å­˜åœ¨
                title = article.get('title', 'Untitled')
                content = article.get('content', '')
                publish_date = article.get('publish_time', '')
                author = article.get('author', 'Unknown')
                url = article.get('url', '')
                
                # è½¬æ¢å‘å¸ƒæ—¥æœŸæ ¼å¼
                if publish_date:
                    publish_date = self.convert_chinese_date_to_iso(publish_date)
                
                # æ›´æ–°æˆ–åˆ›å»ºé¡µé¢
                if self.update_or_create_page(title, content, publish_date, author, url, base_dir):
                    success += 1
                
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
            
            # æ·»åŠ å»¶è¿Ÿä»¥é¿å…è¶…å‡º Notion API é™åˆ¶
            time.sleep(0.5)
        
        print(f"\nå¯¼å…¥å®Œæˆ: {success}/{total} ç¯‡æ–‡ç« æˆåŠŸå¯¼å…¥/æ›´æ–°")

def main():
    # è¿™äº›å€¼éœ€è¦ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ä¸­è·å–
    notion_token = os.getenv("NOTION_TOKEN")
    database_id = os.getenv("NOTION_DATABASE_ID")
    
    if not notion_token or not database_id:
        print("Error: Please set NOTION_TOKEN and NOTION_DATABASE_ID environment variables")
        return

    importer = NotionDatabaseImporter(notion_token, database_id)
    
    # å‡è®¾æˆ‘ä»¬ä½¿ç”¨æœ€æ–°çš„ articles_detailed.json æ–‡ä»¶
    # é¦–å…ˆæ‰¾åˆ°æœ€æ–°çš„æ–‡ç« æ–‡ä»¶å¤¹
    base_dir = "."
    article_folders = [d for d in os.listdir(base_dir) 
                      if d.startswith("articles_batch_") and 
                      os.path.isdir(os.path.join(base_dir, d))]
    
    if not article_folders:
        print("Error: No articles_batch folders found")
        return
    
    # è·å–æœ€æ–°çš„æ–‡ä»¶å¤¹
    latest_folder = max(article_folders)
    json_file = os.path.join(base_dir, latest_folder, "articles_detailed.json")
    
    if not os.path.exists(json_file):
        print(f"Error: {json_file} not found")
        return
    
    print(f"Importing articles from {json_file}")
    importer.import_from_json(json_file)

if __name__ == "__main__":
    main() 